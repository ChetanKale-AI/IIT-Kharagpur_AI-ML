# K-Means Clustering  

This project demonstrates how to perform K-Means clustering using the sklearn package on student marks data. The goal is to cluster students into different groups based on their performance in two subjects. We also explore techniques for evaluating the clustering results and visualizing the data in both 2D and 3D.  

# Introduction  

K-Means clustering is an unsupervised machine learning algorithm that partitions data into K clusters, where each data point belongs to the cluster with the nearest mean. In this project, we perform clustering on student marks and analyze the clustering results using several metrics.  

# Usage  

The code is divided into various sections to visualize the input data, perform clustering, and evaluate the results.  

1. **Data Visualization:** The dataset consists of marks of 22 students for two subjects. The data is visualized as scatter plots.
```python
import matplotlib.pyplot as plt

x = [5, 4, 13, 11, ...]  # Marks in Subject 1
y = [15, 18, 22, 21, ...]  # Marks in Subject 2

plt.scatter(x, y, color='black')
plt.show()
```
![image](https://github.com/user-attachments/assets/dd55573e-42ca-42c3-97da-e0f03851d872)

2. **Data Processing:** The data is formatted as a list of tuples.
```python
data = list(zip(x, y))
print(data)
```
3. **K-Means Clustering:** The data is clustered into two groups (n_clusters=2) using the K-Means algorithm.
```python
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters = 2, n_init = 'auto')
kmeans.fit(data)

c = kmeans.labels_
print(c)
```
4. **Cluster Visualization:** The results of clustering are visualized using color-coded scatter plots.  
```python
plt.scatter(x, y, c = kmeans.labels_)
plt.show()
```
![image](https://github.com/user-attachments/assets/d977997e-a7c2-4e1d-b229-bba835137701)

# Visualization  

Here are some key visualizations used in this project:

- **Scatter Plot of Input Data:** The original data is visualized using a 2D scatter plot to observe the marks distribution.

- **Cluster Visualization:** The clusters generated by K-Means are visualized in color-coded scatter plots.

# Cluster Evaluation  

**1. Silhouette Score:**
The silhouette score measures how similar a point is to its own cluster compared to other clusters. A score close to +1 indicates good clustering.  
```python
from sklearn import metrics
silhouette = metrics.silhouette_score(data, kmeans.labels_, metric='euclidean')
print(silhouette)
# Example output: 0.7214
```
**2. Calinski-Harabasz Index:**
This index evaluates the variance ratio between clusters. A higher score indicates better-defined clusters. 
```python
ch_score = metrics.calinski_harabasz_score(data, kmeans.labels_)
print(ch_score)
# Example output: 121.28
```
**3. Davies-Bouldin Index:**
The Davies-Bouldin index measures cluster similarity. Lower values indicate better clustering. 
```python
db_score = metrics.davies_bouldin_score(data, kmeans.labels_)
print(db_score)
# Example output: 0.38
```
# Elbow Method  

To determine the optimal number of clusters (K), we use the Elbow Method by plotting the inertia (sum of squared errors) for different values of K.  
```python
from sklearn.cluster import KMeans

data = list(zip(x, y))
inertias = []             # SSE / WCSS

for i in range (1, 11):
  kmeans = KMeans(n_clusters = i, n_init = 'auto')
  kmeans.fit(data)
  inertias.append(kmeans.inertia_)

plt.plot (range(1, 11), inertias, marker = 'o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('SSE/WCSS')
plt.show()
```
![image](https://github.com/user-attachments/assets/d1498b49-5e91-47e3-b501-f1e2eaceeecc)

# 3D Clustering  

We also apply K-Means clustering to a 3D dataset (student marks in three subjects) and visualize the results using a 3D scatter plot.  
```python
import matplotlib.pyplot as plt

x = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]
y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]
z = [15, 18, 22, 21, 21, 19, 15, 16, 16, 17]

from mpl_toolkits import mplot3d
ax = plt.axes(projection = "3d")

ax.scatter3D(x, y, z, color = "green")
plt.show()
```
![image](https://github.com/user-attachments/assets/fa43fd0c-dfaa-4324-8efc-db7b918db07f)

# Conclusion  
In this project, we successfully applied K-Means clustering to partition student data based on their performance. We used various metrics like the Silhouette Score, Calinski-Harabasz Index, and Davies-Bouldin Index to evaluate the clustering results. The Elbow Method helped us identify the optimal number of clusters for the dataset. Lastly, we extended the analysis to a 3D dataset.  
